[hflookup-command]
syntax = hflookup model=<string> maxcalls=<integer> continue_on_errors=<boolean> 
shortdesc = Runs the Hugging Face AI Inference API for each input event by passing the event's 'payload' parameter and returns a new event for each result of the API call.
description = Runs the Hugging Face AI Inference API (see https://huggingface.co/inference-api) for each input event by passing the event's 'payload' parameter and returns a new event for each result of the API call. \
    The parameter `model` specifies the ID of the Hugging Face model to use, e.g. 'mschiesser/ner-bert-german'. \
    Pass the api token for the HF API as parameter `api_token` (get yours at hf.co/settings/tokens). \
    If you want to limit the amount of API calls, you can specify a maximum number of calls with the parameter `maxcalls`.\
    If you want to continue on errors, you can specify the parameter `continue_on_errors=true`.
usage = public
comment1 = Runs a german named entity recognition model and yields a prediction for each recognized token.
example1 = | makeresults \
        | eval payload="in m√ºnchen gibt es viele unternehmen, z.b. bmw und siemens."\
        | hflookup model="mschiesser/ner-bert-german" api_token="xxxx"
comment2 = Runs a fill mask model to predict the missing word in a sentence.
example2 = | makeresults \
        | eval payload="The goal of life is [MASK]." \
        | hflookup model="distilbert-base-uncased" api_token="xxxx"