# About

With this app, you can now perform Natural Language Processing tasks directly within Splunk using the powerful [Hugging Face](https://huggingface.co/) or [OpenAI](https://openai.com/) APIs.
Hugging Face is a leading provider of state-of-the-art Natural Language Processing (NLP) models and has been at the forefront of NLP research and development.
This app allows you to leverage the power of Hugging Face's NLP models to analyze unstructured text data within Splunk. You can perform tasks such as sentiment analysis, named entity recognition, and text classification, among others, to gain insights into your data.
Hugging Face provides also over [20k datasets](https://huggingface.co/datasets) which can be easily loaded into Splunk as testdata using this app.
The [OpenAI Embedding API](https://platform.openai.com/docs/guides/embeddings) can be used for generating high-quality vector representations of text, enabling tasks such as semantic similarity, clustering and text classification.

# Usage

Before running any of the commands, please make sure to get an [API token from Hugging Face](http://hf.co/settings/tokens) and configure it in the [setup page](/app/nl_processor/setup).
If you want to use OpenAI embeddings, please get an [API key from OpenAI](https://platform.openai.com/account/api-keys) and configure it also in the [setup page](/app/nl_processor/setup).

## Inference

The `hflookup` command runs the [Hugging Face AI Inference API](https://huggingface.co/inference-api) for each input event by passing the event's `payload` parameter and returns a new event for each result of the API call.

The parameter `model` specifies the ID of the [Hugging Face model](https://huggingface.co/models) to use, e.g. [`mschiesser/ner-bert-german`](https://huggingface.co/mschiesser/ner-bert-german).
If you want to limit the amount of API calls, you can specify a maximum number of calls with the parameter `maxcalls`.
If you want to continue on errors, you can specify the parameter `continue_on_errors=true`.

## Loading Datasets

The `hfdataset` command runs the [Hugging Face Datasets API](https://huggingface.co/docs/datasets-server/index) to retrieve test data from the [datasets from Hugging Face](https://huggingface.co/datasets).
The parameter `dataset` specifies the name of the dataset to download, e.g. [`yelp_review_full`](https://huggingface.co/datasets/yelp_review_full).
Per default, the `train` split of the dataset is used. If you want to set another split (e.g. the `test` split), use the `split` parameter.

## OpenAI Embeddings

The `openaiembeddings` command runs the [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings) to retrieve embeddings for each input event.
The parameter `input_field` defines the name of the field that contains the text for which an embedding should be calculated. The embedding is stored in the `embedding` field for each event.
Per default the model `text-embedding-ada-002` is used - this can be changed with the `model` parameter.
If you want to limit the amount of API calls, you can specify a maximum number of calls with the parameter `maxcalls`.
If you want to continue on errors, you can specify the parameter `continue_on_errors=true`.


# Examples

Note that some models in Hugging Face are not often used and therefore loaded on-demand. If you're getting a `Model ... is currently loading` error, please try again after half a minute.

## Named Entity Recognition

The following example is using [named-entity recognition](https://en.wikipedia.org/wiki/Named-entity_recognition), to extract the location, names, and organizations of the string given as `payload`:

    | makeresults
    | eval payload="My name is Clara and I live in San Jose, California and I am working there for Splunk."
    | hflookup model="Jean-Baptiste/roberta-large-ner-english"

You can also try another model, to do named-entity recognition in German:

    | makeresults
    | eval payload="in MÃ¼nchen gibt es viele Unternehmen, z.b. BMW und Siemens."
    | hflookup model="mschiesser/ner-bert-german"

## Sentiment Analysis

The following example is using [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis), to extract the sentiment of the sentence given as `payload`:

    | makeresults
    | eval payload="Covid cases are increasing fast!"
    | hflookup model="cardiffnlp/twitter-roberta-base-sentiment-latest"

## Embeddings

The following example is generating an [embedding](https://en.wikipedia.org/wiki/Word_embedding) for the text in the field `input`:

    | makeresults
    | eval input="Covid cases are increasing fast!"
    | openaiembeddings input_field=input

# Contact

To run the command in production, you might want to:

1. Cache the results to limit the number of API calls
2. Run the inference in your own cloud or data center for security reasons
3. Train new AI models fitting the needs of your use cases
4. Set up a [MLOps](https://en.wikipedia.org/wiki/MLOps) pipeline for Splunk to update your AI models during run-time.

Feel free to [contact me](mailto:mail@marcusschiesser.de) for any of these problems. My team and I are glad to help.

# Binary File Declaration

This app is using the Python bindings for the binary library [snappy](https://github.com/google/snappy), [python-snappy](https://github.com/andrix/python-snappy/tree/0.6.1) in version 0.6.1, to read compressed [parquet](https://parquet.apache.org/) files from Hugging Face.
